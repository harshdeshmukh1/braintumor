{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zl0y_UlhmyU",
        "outputId": "8d53ab22-452d-4073-8e16-7b7b898c71b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "masoudnickparvar_brain_tumor_mri_dataset_path = kagglehub.dataset_download('masoudnickparvar/brain-tumor-mri-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j55AE9Y7w-oM"
      },
      "source": [
        "**IMPORTING LIBRARIES AND DEFINING DIRECTORIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-10T02:32:36.599537Z",
          "iopub.status.busy": "2025-06-10T02:32:36.598644Z",
          "iopub.status.idle": "2025-06-10T02:32:36.605575Z",
          "shell.execute_reply": "2025-06-10T02:32:36.604757Z",
          "shell.execute_reply.started": "2025-06-10T02:32:36.599509Z"
        },
        "id": "GvBe9QTXhmyX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import VGG16, ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-10T02:32:36.606989Z",
          "iopub.status.busy": "2025-06-10T02:32:36.606783Z",
          "iopub.status.idle": "2025-06-10T02:32:36.624869Z",
          "shell.execute_reply": "2025-06-10T02:32:36.624177Z",
          "shell.execute_reply.started": "2025-06-10T02:32:36.606972Z"
        },
        "id": "nZpZUd-thmyX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_dir = '/kaggle/input/brain-tumor-mri-dataset/Training'\n",
        "test_dir = '/kaggle/input/brain-tumor-mri-dataset/Testing'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-10T02:32:36.625775Z",
          "iopub.status.busy": "2025-06-10T02:32:36.625583Z",
          "iopub.status.idle": "2025-06-10T02:32:36.638859Z",
          "shell.execute_reply": "2025-06-10T02:32:36.638267Z",
          "shell.execute_reply.started": "2025-06-10T02:32:36.625758Z"
        },
        "id": "xmZFyzDfhmyY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (150, 150)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC6-EjpAxcSP"
      },
      "source": [
        "**Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-10T02:32:36.640326Z",
          "iopub.status.busy": "2025-06-10T02:32:36.640084Z",
          "iopub.status.idle": "2025-06-10T02:32:37.247836Z",
          "shell.execute_reply": "2025-06-10T02:32:37.247074Z",
          "shell.execute_reply.started": "2025-06-10T02:32:36.640309Z"
        },
        "id": "rFWZcqXhhmyY",
        "outputId": "bdc203ca-5926-4de2-f1a8-75bd7d78df77",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=20,\n",
        "                                   zoom_range=0.2,\n",
        "                                   width_shift_range=0.1,\n",
        "                                   height_shift_range=0.1,\n",
        "                                   horizontal_flip=True,\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=IMG_SIZE,\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    subset='training',\n",
        "                                                    shuffle=True)\n",
        "\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                         target_size=IMG_SIZE,\n",
        "                                                         batch_size=BATCH_SIZE,\n",
        "                                                         class_mode='categorical',\n",
        "                                                         subset='validation',\n",
        "                                                         shuffle=False)\n",
        "\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=IMG_SIZE,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-10T02:32:37.248908Z",
          "iopub.status.busy": "2025-06-10T02:32:37.248682Z",
          "iopub.status.idle": "2025-06-10T02:32:37.252631Z",
          "shell.execute_reply": "2025-06-10T02:32:37.251889Z",
          "shell.execute_reply.started": "2025-06-10T02:32:37.248891Z"
        },
        "id": "rXPDqgwWhmyY",
        "outputId": "dd27458f-d5f6-4a17-d03d-259d42798e0d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class_labels = list(train_generator.class_indices.keys())\n",
        "num_classes = len(class_labels)\n",
        "samples_per_class = 3\n",
        "print(num_classes)\n",
        "print(class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2025-06-10T02:32:37.253673Z",
          "iopub.status.busy": "2025-06-10T02:32:37.253434Z",
          "iopub.status.idle": "2025-06-10T02:32:38.569649Z",
          "shell.execute_reply": "2025-06-10T02:32:38.56862Z",
          "shell.execute_reply.started": "2025-06-10T02:32:37.253655Z"
        },
        "id": "EixnfXkshmyZ",
        "outputId": "e41ed290-8c1f-495c-830c-9c0b4e4bca2a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(samples_per_class * 3, num_classes * 3))  # Create a large canvas\n",
        "\n",
        "for idx, class_label in enumerate(class_labels):  # Loop over each class name\n",
        "\n",
        "    # Find the corresponding class index (e.g., 'dog' â†’ 1)\n",
        "    class_index = train_generator.class_indices[class_label]\n",
        "\n",
        "    # Get the full list of file paths and class indices from the generator\n",
        "    filepaths = train_generator.filepaths\n",
        "    classes = train_generator.classes\n",
        "\n",
        "    # Filter the indices that belong to the current class\n",
        "    indices = [i for i, c in enumerate(classes) if c == class_index]\n",
        "\n",
        "    # Select the first few examples (e.g., 3 images) of this class\n",
        "    selected = indices[:samples_per_class]\n",
        "\n",
        "    # Loop through the selected image indices\n",
        "    for j, i in enumerate(selected):\n",
        "        img_path = filepaths[i]                                # Get the image path\n",
        "        img = load_img(img_path, target_size=IMG_SIZE)         # Load and resize the image\n",
        "        img_arr = img_to_array(img) / 255.0                    # Convert to array and normalize\n",
        "\n",
        "        # Plot the image in a subplot\n",
        "        ax = plt.subplot(num_classes, samples_per_class, idx * samples_per_class + j + 1)\n",
        "        ax.imshow(img_arr.astype('float32'))                   # Show the image\n",
        "        ax.set_title(f'{class_label}')                         # Show the class name\n",
        "        ax.axis('off')                                         # Hide axis ticks\n",
        "\n",
        "# Add a title above all subplots\n",
        "plt.suptitle('Examples of Training Images per Class', fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout so nothing overlaps\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "execution": {
          "iopub.execute_input": "2025-06-10T02:32:38.570733Z",
          "iopub.status.busy": "2025-06-10T02:32:38.570511Z",
          "iopub.status.idle": "2025-06-10T02:32:38.750974Z",
          "shell.execute_reply": "2025-06-10T02:32:38.750198Z",
          "shell.execute_reply.started": "2025-06-10T02:32:38.570715Z"
        },
        "id": "nBEbVFKEhmyZ",
        "outputId": "63cb7ff5-7ed4-4e5e-cd34-50f11835ef54",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class_labels = list(train_generator.class_indices.keys())\n",
        "train_classes = train_generator.classes\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x=[class_labels[c] for c in train_classes])\n",
        "plt.title('Class Distribution in the Training Set')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-10T02:32:38.751991Z",
          "iopub.status.busy": "2025-06-10T02:32:38.751777Z",
          "iopub.status.idle": "2025-06-10T02:32:38.758821Z",
          "shell.execute_reply": "2025-06-10T02:32:38.758038Z",
          "shell.execute_reply.started": "2025-06-10T02:32:38.751972Z"
        },
        "id": "Az3GHXjKhmyZ",
        "outputId": "28e277c6-b4ab-4e6e-97a9-e1d1304961e0",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights: {0: np.float64(1.0811258278145695), 1: np.float64(1.0659981343283582), 2: np.float64(0.8955721003134797), 3: np.float64(0.9800600343053173)}\n"
          ]
        }
      ],
      "source": [
        "# Compute class weights to balance training classes (optional)\n",
        "class_weights_vals = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_classes),\n",
        "    y=train_classes\n",
        ")\n",
        "\n",
        "class_weights_dict = {i: class_weights_vals[i] for i in range(len(class_weights_vals))}\n",
        "print('Class weights:', class_weights_dict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEajXaZ8zRHz"
      },
      "source": [
        "**BUILDING CUSTOM CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "execution": {
          "iopub.execute_input": "2025-06-10T02:32:38.761581Z",
          "iopub.status.busy": "2025-06-10T02:32:38.761379Z",
          "iopub.status.idle": "2025-06-10T02:32:40.003105Z",
          "shell.execute_reply": "2025-06-10T02:32:40.002571Z",
          "shell.execute_reply.started": "2025-06-10T02:32:38.761565Z"
        },
        "id": "AHBKCdxchmya",
        "outputId": "62df476e-0342-43bf-8dab-a02c4d4412fa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Conv2D, MaxPooling2D, Flatten\n",
        "\n",
        "# Building a deeper CNN with Batch Normalization\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(class_labels), activation='softmax')  # Output layer for multi-class classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model architecture\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-10T02:32:40.00437Z",
          "iopub.status.busy": "2025-06-10T02:32:40.004081Z"
        },
        "id": "Psy6YrH9hmya",
        "outputId": "23b3ef01-81f9-494d-cc5d-59353fabc0d6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# Callbacks for early stopping and learning rate reduction\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stop, lr_reduce]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMoK3LIBdPwf"
      },
      "source": [
        "**PLOTS AND TEST ACCURACY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0ndk_9bhmya",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plot training and validation curves (accuracy and loss)\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Accuracy curve\n",
        "sns.lineplot(ax=axs[0], x=range(1, len(history.history['accuracy']) + 1), y=history.history['accuracy'], label='Training', color='blue')\n",
        "sns.lineplot(ax=axs[0], x=range(1, len(history.history['val_accuracy']) + 1), y=history.history['val_accuracy'], label='Validation', color='red')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('Accuracy')\n",
        "axs[0].set_title('Training and Validation Accuracy')\n",
        "axs[0].legend()\n",
        "\n",
        "# Loss curve\n",
        "sns.lineplot(ax=axs[1], x=range(1, len(history.history['loss']) + 1), y=history.history['loss'], label='Training Loss', color='orange')\n",
        "sns.lineplot(ax=axs[1], x=range(1, len(history.history['val_loss']) + 1), y=history.history['val_loss'], label='Validation Loss', color='purple')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('Loss')\n",
        "axs[1].set_title('Training and Validation Loss')\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SouxqXLghmya",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idQh1ZXlhmya",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Predictions on the test set\n",
        "predictions = model.predict(test_generator)\n",
        "\n",
        "# Get the class with the highest probability for each sample\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get the true class labels from the test set\n",
        "true_classes = test_generator.classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DmextIxhmya",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d',\n",
        "            xticklabels=class_labels,\n",
        "            yticklabels=class_labels,\n",
        "            cmap='Blues')\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyXXn62Lhmya",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Classification report: shows precision, recall, f1-score for each class\n",
        "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yghmysu-hmyb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Visualizing some predictions using subplots\n",
        "num_rows = 3\n",
        "num_cols = 3\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Ensure there are enough test images\n",
        "total_test = len(test_generator.filenames)\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    if i >= total_test:\n",
        "        break\n",
        "\n",
        "    # Get a batch from the generator\n",
        "    img_batch, label_batch = test_generator[i]\n",
        "\n",
        "    # Get the first image and its labels\n",
        "    img = img_batch[0]\n",
        "    true_label = np.argmax(label_batch[0])  # Convert one-hot to class index\n",
        "    pred_label = predicted_classes[i]       # Already computed from model.predict()\n",
        "\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(f'True: {class_labels[true_label]}\\nPred: {class_labels[pred_label]}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E0nUjE_hmyb"
      },
      "source": [
        "** Model 2 â€“ Using Pre-trained VGG16 or ResNet50**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbHn8nkchmyb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Directories\n",
        "train_dir = '/kaggle/input/brain-tumor-mri-dataset/Training'\n",
        "test_dir = '/kaggle/input/brain-tumor-mri-dataset/Testing'\n",
        "# Parameters\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXi7dprLhmyc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Data augmentation for training, with 20% validation split\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,             # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,          # Random rotation up to Â±20 degrees\n",
        "    zoom_range=0.2,             # Random zoom up to Â±20%\n",
        "    width_shift_range=0.1,      # Horizontal shift up to 10%\n",
        "    height_shift_range=0.1,     # Vertical shift up to 10%\n",
        "    horizontal_flip=True,       # Random horizontal flip\n",
        "    validation_split=0.2        # Reserve 20% of training data for validation\n",
        ")\n",
        "\n",
        "# Only rescaling for test data (no augmentation)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Training data generator (80% of train_dir)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training',          # Use only the training part\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Validation data generator (20% of train_dir)\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',        # Use only the validation part\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Test data generator (from separate test_dir)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYwGBUyFhmyc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "train_classes = train_generator.classes\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x=[class_labels[c] for c in train_classes])\n",
        "plt.title('Class Distribution in Training Set')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgrEzIBghmyc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Compute class weights to handle class imbalance\n",
        "class_weights_vals = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_classes),\n",
        "    y=train_classes\n",
        ")\n",
        "class_weights_dict = {i: class_weights_vals[i] for i in range(len(class_weights_vals))}\n",
        "print('Class weights:', class_weights_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fITGnrBihmyc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Callbacks to stop early and reduce learning rate when validation loss plateaus\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
        "\n",
        "# Function to build a transfer learning model\n",
        "def build_model(base_name, input_shape, num_classes, freeze_layers=True):\n",
        "\n",
        "    # Load the selected pretrained model without top layers\n",
        "    if base_name == 'VGG16':\n",
        "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    elif base_name == 'ResNet50':\n",
        "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    else:\n",
        "        raise ValueError(f\"Base model {base_name} not supported\")\n",
        "\n",
        "    # Optionally freeze base model layers\n",
        "    if freeze_layers:\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "    # Add custom classification head\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Build and compile the full model\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oS5hBHzmhmyc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# Training and storing results\n",
        "results = {}\n",
        "input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3)\n",
        "num_classes = len(class_labels)\n",
        "\n",
        "for base_name in ['VGG16', 'ResNet50']:\n",
        "    print(f\"\\nTraining model with base {base_name}...\")\n",
        "\n",
        "    model = build_model(base_name, input_shape, num_classes, freeze_layers=True)\n",
        "\n",
        "    history = model.fit(train_generator,\n",
        "                        epochs=EPOCHS,\n",
        "                        validation_data=validation_generator)\n",
        "\n",
        "    # Evaluation on test set\n",
        "    test_loss, test_acc = model.evaluate(test_generator)\n",
        "    print(f'{base_name} - Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}')\n",
        "\n",
        "    # Predictions on test set\n",
        "    predictions = model.predict(test_generator)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    true_classes = test_generator.classes\n",
        "\n",
        "    # Store in results\n",
        "    results[base_name] = {\n",
        "        'model': model,\n",
        "        'history': history,\n",
        "        'predictions': predictions,\n",
        "        'predicted_classes': predicted_classes,\n",
        "        'true_classes': true_classes\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "827Zoyq3hmyc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plot training curves (accuracy and loss) for VGG16\n",
        "\n",
        "history = results['VGG16']['history']  # Use VGG16 history; change key to plot other models\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot accuracy\n",
        "sns.lineplot(ax=axs[0], x=range(1, len(history.history['accuracy']) + 1),\n",
        "             y=history.history['accuracy'], label='Training', color='blue')\n",
        "sns.lineplot(ax=axs[0], x=range(1, len(history.history['val_accuracy']) + 1),\n",
        "             y=history.history['val_accuracy'], label='Validation', color='red')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('Accuracy')\n",
        "axs[0].set_title('Accuracy - VGG16')\n",
        "axs[0].legend()\n",
        "\n",
        "# Plot loss\n",
        "sns.lineplot(ax=axs[1], x=range(1, len(history.history['loss']) + 1),\n",
        "             y=history.history['loss'], label='Training Loss', color='orange')\n",
        "sns.lineplot(ax=axs[1], x=range(1, len(history.history['val_loss']) + 1),\n",
        "             y=history.history['val_loss'], label='Validation Loss', color='purple')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('Loss')\n",
        "axs[1].set_title('Loss - VGG16')\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0B2200ogrwW"
      },
      "outputs": [],
      "source": [
        "# Plot training curves (accuracy and loss) for ResNet50\n",
        "\n",
        "history = results['ResNet50']['history']  # Use ResNet50 history\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Accuracy plot\n",
        "sns.lineplot(ax=axs[0], x=range(1, len(history.history['accuracy']) + 1),\n",
        "             y=history.history['accuracy'], label='Training', color='blue')\n",
        "sns.lineplot(ax=axs[0], x=range(1, len(history.history['val_accuracy']) + 1),\n",
        "             y=history.history['val_accuracy'], label='Validation', color='red')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('Accuracy')\n",
        "axs[0].set_title('Accuracy - ResNet50')\n",
        "axs[0].legend()\n",
        "\n",
        "# Loss plot\n",
        "sns.lineplot(ax=axs[1], x=range(1, len(history.history['loss']) + 1),\n",
        "             y=history.history['loss'], label='Training Loss', color='orange')\n",
        "sns.lineplot(ax=axs[1], x=range(1, len(history.history['val_loss']) + 1),\n",
        "             y=history.history['val_loss'], label='Validation Loss', color='purple')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('Loss')\n",
        "axs[1].set_title('Loss - ResNet50')\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyAzvByRhmyc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# 1. Confusion Matrices for each model\n",
        "for base_name, res in results.items():\n",
        "    cm = confusion_matrix(res['true_classes'], res['predicted_classes'])\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d',\n",
        "                xticklabels=class_labels,\n",
        "                yticklabels=class_labels,\n",
        "                cmap='Blues')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(f'Confusion Matrix - {base_name}')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vfnyufr8hmyd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# 2. Classification Report\n",
        "for base_name, res in results.items():\n",
        "    print(f'Classification report - {base_name}:')\n",
        "    report = classification_report(res['true_classes'], res['predicted_classes'], target_names=class_labels)\n",
        "    print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSQM4d1Yhmyd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# 3. ROC Curves\n",
        "for base_name, res in results.items():\n",
        "    # Convert true labels to one-hot encoded format\n",
        "    y_true_bin = label_binarize(res['true_classes'], classes=list(range(num_classes)))\n",
        "    y_score = res['predictions']  # Model's predicted probabilities\n",
        "\n",
        "    fpr = dict()  # False Positive Rates\n",
        "    tpr = dict()  # True Positive Rates\n",
        "    roc_auc = dict()  # Area Under Curve for each class\n",
        "\n",
        "    # Compute FPR, TPR, and AUC for each class\n",
        "    for i in range(num_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_score[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Plot ROC curves\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i in range(num_classes):\n",
        "        plt.plot(fpr[i], tpr[i], label=f'{class_labels[i]} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "    # Add diagonal line for reference (random guessing)\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "\n",
        "    # Format plot\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curves - {base_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_sx-cbEhmyd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# 4. Predictions in Subplots (Examples)\n",
        "for base_name, res in results.items():\n",
        "    print(f'Prediction examples - {base_name}')\n",
        "    num_rows, num_cols = 3, 3\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 12))\n",
        "    axes = axes.flatten()\n",
        "    total_test = len(test_generator.filenames)\n",
        "\n",
        "    for i, ax in enumerate(axes):\n",
        "        if i >= total_test:\n",
        "            break\n",
        "        # Load the image for display\n",
        "        img_path = test_generator.filepaths[i]\n",
        "        img = load_img(img_path, target_size=IMG_SIZE)\n",
        "        img_arr = img_to_array(img) / 255.0\n",
        "        true_label = res['true_classes'][i]\n",
        "        pred_label = res['predicted_classes'][i]\n",
        "\n",
        "        ax.imshow(img_arr.astype('float32'))\n",
        "        ax.set_title(f'True: {class_labels[true_label]}\\nPred: {class_labels[pred_label]}')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.suptitle(f'Test Set Predictions - {base_name}', fontsize=16)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By5oVb1Thmyd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# 5. Comparison of Validation Accuracy between architectures\n",
        "plt.figure(figsize=(8, 6))\n",
        "for base_name, res in results.items():\n",
        "    hist = res['history']\n",
        "    sns.lineplot(\n",
        "        x=range(1, len(hist.history['val_accuracy']) + 1),\n",
        "        y=hist.history['val_accuracy'],\n",
        "        label=f'Val Acc - {base_name}'\n",
        "    )\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Validation Accuracy Comparison')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a09Xi2Thmyd",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 1608934,
          "sourceId": 2645886,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
